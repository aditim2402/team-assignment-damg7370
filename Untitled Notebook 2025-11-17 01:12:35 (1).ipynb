{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4d9c0d86-15e4-4b05-93fb-f5f38569a567",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark import pipelines as pl\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import (\n",
    "    StructType,\n",
    "    StructField,\n",
    "    StringType,\n",
    "    MapType,\n",
    "    LongType,\n",
    ")\n",
    "\n",
    "\n",
    "volume_path = \"/Volumes/workspace/damg7370/datastore/schema_drift/schema_drift_fresh\"\n",
    "\n",
    "schema_location_addcols = \"/Volumes/workspace/damg7370/datastore/schema_drift/schema_location_addcols\"\n",
    "\n",
    "bronze_schema_rescue = StructType([\n",
    "    StructField(\"CustomerID\",  StringType(), True),\n",
    "    StructField(\"Name\",        StringType(), True),\n",
    "    StructField(\"Email\",       StringType(), True),\n",
    "    StructField(\"PhoneNumber\", StringType(), True),\n",
    "    StructField(\"City\",        StringType(), True),\n",
    "    StructField(\"signupDate\",  StringType(), True),   # note: string here\n",
    "    StructField(\"CreditScore\", StringType(), True),   # can start as string\n",
    "])\n",
    "\n",
    "# Datatypes we want in Silver (for RESCUE path)\n",
    "updated_datatypes = {\n",
    "    \"SignupDate\": \"date\",\n",
    "    \"CreditScore\": \"double\",\n",
    "}\n",
    "\n",
    "pl.create_streaming_table(\"demo_cust_bronze_sd\")\n",
    "\n",
    "@pl.append_flow(\n",
    "    target=\"demo_cust_bronze_sd\",\n",
    "    name=\"demo_cust_bronze_sd_ingest_flow\"\n",
    ")\n",
    "def demo_cust_bronze_sd_ingest_flow():\n",
    "    df = (\n",
    "        spark.readStream\n",
    "            .format(\"cloudFiles\")\n",
    "            .option(\"cloudFiles.format\", \"json\")\n",
    "            .option(\"cloudFiles.inferColumnTypes\", \"false\")\n",
    "            .option(\"cloudFiles.schemaEvolutionMode\", \"rescue\")\n",
    "            .option(\"rescuedDataColumn\", \"_rescued_data\")\n",
    "            .schema(bronze_schema_rescue)\n",
    "            .load(volume_path)\n",
    "    )\n",
    "\n",
    "    # Add metadata columns\n",
    "    df = (\n",
    "        df.withColumn(\"ingestion_datetime\", F.current_timestamp())\n",
    "          .withColumn(\"source_filename\", F.col(\"_metadata.file_path\"))\n",
    "    )\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def process__rescue_data_new_fields(df):\n",
    "    \"\"\"\n",
    "    Extract fields out of `_rescued_data` and populate proper columns.\n",
    "    Only add new columns if they do not already exist in the DataFrame.\n",
    "    \"\"\"\n",
    "    if \"_rescued_data\" not in df.columns:\n",
    "        return df\n",
    "\n",
    "    # Parse JSON string into MAP<string,string>\n",
    "    df = df.withColumn(\n",
    "        \"_rescued_map\",\n",
    "        F.from_json(F.col(\"_rescued_data\"), MapType(StringType(), StringType()))\n",
    "    )\n",
    "\n",
    "    # Map: key in JSON -> desired column name\n",
    "    field_map = {\n",
    "        \"CustomerID\":    \"CustomerID\",\n",
    "        \"CustomerId\":    \"CustomerID\",\n",
    "        \"FullName\":      \"Name\",\n",
    "        \"Name\":          \"Name\",\n",
    "        \"Email\":         \"Email\",\n",
    "        \"PhoneNumber\":   \"PhoneNumber\",\n",
    "        \"City\":          \"City\",\n",
    "        \"SignupDate\":    \"SignupDate\",\n",
    "        \"signupDate\":    \"SignupDate\",\n",
    "        \"Age\":           \"Age\",\n",
    "        \"Gender\":        \"Gender\",\n",
    "        \"LoyaltyStatus\": \"LoyaltyStatus\",\n",
    "        \"CreditScore\":   \"CreditScore\",\n",
    "    }\n",
    "\n",
    "    # Only add rescued columns if they do not already exist\n",
    "    for src_key, dest_col in field_map.items():\n",
    "        if dest_col in df.columns:\n",
    "            # If column exists, update it with rescued value if null\n",
    "            df = df.withColumn(\n",
    "                dest_col,\n",
    "                F.coalesce(\n",
    "                    F.col(dest_col),\n",
    "                    F.col(\"_rescued_map\").getItem(src_key)\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            # If column does not exist, add it from rescued map if present\n",
    "            df = df.withColumn(\n",
    "                dest_col,\n",
    "                F.col(\"_rescued_map\").getItem(src_key)\n",
    "            )\n",
    "\n",
    "    # Drop helper column\n",
    "    df = df.drop(\"_rescued_map\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def process__rescue_data_datatype_change(df, target_schema_map: dict):\n",
    "    \"\"\"\n",
    "    Convert selected columns to their target datatypes in Silver.\n",
    "    \"\"\"\n",
    "    for col_name, target_type in target_schema_map.items():\n",
    "        if col_name not in df.columns:\n",
    "            continue\n",
    "\n",
    "        if target_type.lower() == \"date\":\n",
    "            df = df.withColumn(col_name, F.to_date(F.col(col_name)))\n",
    "        elif target_type.lower() in (\"double\", \"float\"):\n",
    "            df = df.withColumn(col_name, F.col(col_name).cast(\"double\"))\n",
    "        elif target_type.lower() in (\"int\", \"integer\"):\n",
    "            df = df.withColumn(col_name, F.col(col_name).cast(\"int\"))\n",
    "        else:\n",
    "            df = df.withColumn(col_name, F.col(col_name).cast(\"string\"))\n",
    "\n",
    "    return df\n",
    "\n",
    "pl.create_streaming_table(\"demo_cust_silver_rescue\")\n",
    "\n",
    "@pl.append_flow(\n",
    "    target=\"demo_cust_silver_rescue\",\n",
    "    name=\"demo_cust_silver_rescue_flow\"\n",
    ")\n",
    "def demo_cust_silver_rescue_flow():\n",
    "    # Use pl.read_stream so graph shows Bronze -> Silver link\n",
    "    df = pl.read_stream(\"demo_cust_bronze_sd\")\n",
    "\n",
    "    # 1) Pull fields out of _rescued_data\n",
    "    df = process__rescue_data_new_fields(df)\n",
    "\n",
    "    # 2) Fix datatypes (SignupDate -> date, CreditScore -> double)\n",
    "    df = process__rescue_data_datatype_change(df, updated_datatypes)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "78c5d784-57d4-4202-bb14-fa362910b1e2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Untitled Notebook 2025-11-17 01:12:35 (1)",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
